{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required package\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree     import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations data preparation\n",
    "weatherdf = pd.read_csv('static/weatherdata.csv',  keep_default_na=True, sep=',\\s+', delimiter=',')\n",
    "weatherdf[\"new_dateframe\"] = pd.to_datetime(weatherdf[\"dt\"], unit=\"s\")\n",
    "weatherdf[\"hour\"]= weatherdf[\"new_dateframe\"].dt.hour\n",
    "weatherdf[\"date\"]= weatherdf[\"new_dateframe\"].dt.date\n",
    "weatherdf = weatherdf.drop(['humidity','pressure','temp_max','temp_min','description', 'icon', 'id', 'wind_deg', 'new_dateframe' ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather data preparation\n",
    "bikedf = pd.read_csv('static/bikesdata.csv',  keep_default_na=True, sep=',\\s+', delimiter=',')\n",
    "bikedf[\"new_dateframe\"] = pd.to_datetime(bikedf[\"last_update\"], unit=\"ms\")\n",
    "bikedf[\"hour\"]= bikedf[\"new_dateframe\"].dt.hour\n",
    "bikedf[\"date\"]= bikedf[\"new_dateframe\"].dt.date\n",
    "bikedf = bikedf.drop(['last_update','banking','bike_stands','status', 'new_dateframe','contract_name', 'address', 'position_lat', 'position_lng', 'bonus', 'name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing for random forest\n",
    "mergedf=pd.merge(bikedf,weatherdf,on=['hour','date'], how = \"left\")\n",
    "mergedf = mergedf.dropna()\n",
    "mergedf=mergedf.drop(['date'], axis = 1)\n",
    "categorical_columns = mergedf[['main']].columns\n",
    "for column in categorical_columns:\n",
    "    mergedf[column] = mergedf[column].astype('category')\n",
    "mergedf= pd.get_dummies(mergedf, columns=['main'], prefix = ['main'])\n",
    "mergedf.duplicated()\n",
    "mergedf=mergedf.drop_duplicates()\n",
    "mergedf = mergedf.drop(['main_Clouds','main_Clear','available_bike_stands','dt'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select numeric features\n",
    "numeric_columns = mergedf.select_dtypes(['int64','float64','uint8']).columns\n",
    "numeric_columns = numeric_columns.drop(['available_bikes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = mergedf.select_dtypes(['int64','float64','uint8']).columns\n",
    "X = mergedf[numeric_columns]\n",
    "y = mergedf.available_bikes\n",
    "print(\"\\nDescriptive features in X:\\n\", X)\n",
    "print(\"\\nTarget feature in y:\\n\", y)\n",
    "linreg_70train = LinearRegression().fit(X, y)\n",
    "print(\"Features: \\n\", X.columns)\n",
    "print(\"Coeficients: \\n\", linreg_70train.coef_)\n",
    "print(\"\\nIntercept: \\n\", linreg_70train.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up prediction variables\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y)\n",
    "y_predicted = linreg_70train.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print out format\n",
    "def printMetrics(testActualVal, predictions):\n",
    "    print('\\n==============================================================================')\n",
    "    print(\"MAE: \", metrics.mean_absolute_error(testActualVal, predictions))\n",
    "    print(\"RMSE: \", metrics.mean_squared_error(testActualVal, predictions)**0.5)\n",
    "    print(\"R2: \", metrics.r2_score(testActualVal, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start training \n",
    "for i in mergedf.number.unique():\n",
    "    mergedf_id = mergedf.loc[mergedf[\"number\"] == i]\n",
    "    numeric_columns = mergedf_id.select_dtypes(['int64','float64','uint8']).columns\n",
    "    numeric_columns = numeric_columns.drop(['available_bikes'])\n",
    "    X = mergedf_id[numeric_columns]\n",
    "    y = mergedf_id.available_bikes\n",
    "    # set up random forest arguement\n",
    "    random_forest = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=500)\n",
    "    # 2/3 data training 1/3 data testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=42)\n",
    "    random_forest.fit(X_train,y_train)\n",
    "    y_predicted = random_forest.predict(X_test)\n",
    "    # generate pickle files\n",
    "    pkl_filename = str(i) + \".pkl\"  \n",
    "    with open('static/pickle/' + pkl_filename, 'wb') as file:\n",
    "        pickle.dump(random_forest, file)\n",
    "    actual_vs_predicted_multiplelinreg1 = pd.concat([y_test,pd.DataFrame(y_predicted, columns=['Predicted'],index=y_test.index)],axis=1)\n",
    "    print(printMetrics(y_test,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "def bikes_prediction(station_id,time_hour):\n",
    "    r = requests.get('http://api.openweathermap.org/data/2.5/forecast?appid=9511c6f09bf671d3bd65bf650197234f&q=Dublin')\n",
    "    weathers = r.json()               \n",
    "    weather_detalis = weathers[\"list\"]                                                                                           \n",
    "    temp = weather_detalis[0]['main']['temp']                                                                                    \n",
    "    wind = weather_detalis[0]['wind']['speed']                                                                                   \n",
    "    main = weather_detalis[0]['weather'][0]['main']                                                                                  \n",
    "    weather_Drizzle = 0\n",
    "    weather_Rain = 0\n",
    "    if main == 'Drizzle':\n",
    "        weather_Drizzle = 1\n",
    "    elif main == 'Rain':\n",
    "        weather_Rain = 1\n",
    "    f2 = pd.DataFrame(np.array([station_id,time_hour, temp, wind, weather_Drizzle, weather_Rain])).T\n",
    "    models = {}\n",
    "    with open(str(station_id) + \".pkl\", \"rb\") as handle:\n",
    "        models[station_id] = pickle.load(handle)\n",
    "    return models[station_id].predict(f2).round()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "bikes_prediction(12,13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
